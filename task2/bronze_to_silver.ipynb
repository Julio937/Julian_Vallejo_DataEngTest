{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9980fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Standard library modules for filesystem paths, regex parsing, and numerical utilities ───\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# ─── Third-party libraries for PDF parsing and tabular data handling ───\n",
    "import pdfplumber\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b07286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_tables_long(pdf_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Open a PDF, extract every table, normalize into a long form DataFrame,\n",
    "    and return a concatenation of all table records.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    tbl_counter = 0\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # iterate over every page\n",
    "        for page in pdf.pages:\n",
    "            # extract raw table data per page\n",
    "            for raw in page.extract_tables():\n",
    "                tbl_counter += 1\n",
    "                if not raw or len(raw) < 2:\n",
    "                    continue  # skip empty or single-row tables\n",
    "\n",
    "                # find where actual data rows start (first non-blank in column 0)\n",
    "                start_row = next(\n",
    "                    (i for i in range(2, len(raw)) if (raw[i][0] or \"\").strip()),\n",
    "                    None\n",
    "                )\n",
    "                if start_row is None:\n",
    "                    continue\n",
    "\n",
    "                # combine all header rows above start_row into flat column names\n",
    "                header_rows = raw[:start_row]\n",
    "                num_cols = len(header_rows[0])\n",
    "                headers = []\n",
    "                for col in range(num_cols):\n",
    "                    parts = [\n",
    "                        (hr[col] or \"\").replace(\"\\n\", \" \").strip()\n",
    "                        for hr in header_rows\n",
    "                        if (hr[col] or \"\").strip()\n",
    "                    ]\n",
    "                    headers.append(\" \".join(parts))\n",
    "\n",
    "                # build a DataFrame for the data portion\n",
    "                data_rows = raw[start_row:]\n",
    "                df = pd.DataFrame(data_rows, columns=headers)\n",
    "\n",
    "                # detect if there’s a currency column by name\n",
    "                currency_cols = [c for c in headers if re.search(r'Currency', c, re.IGNORECASE)]\n",
    "                if currency_cols:\n",
    "                    cur_col = currency_cols[0]\n",
    "                    idx_cur = headers.index(cur_col)\n",
    "                    id_vars = headers[:idx_cur+1]       # include row_label + currency\n",
    "                    default_currency = None\n",
    "                else:\n",
    "                    cur_col = None\n",
    "                    id_vars = [headers[0]]              # only row_label\n",
    "                    default_currency = \"USD\"\n",
    "\n",
    "                # remaining columns become value columns\n",
    "                value_vars = [c for c in headers if c not in id_vars]\n",
    "\n",
    "                # melt into long form with raw values\n",
    "                long = df.melt(\n",
    "                    id_vars=id_vars,\n",
    "                    value_vars=value_vars,\n",
    "                    var_name=\"column_header\",\n",
    "                    value_name=\"v_raw\"\n",
    "                )\n",
    "\n",
    "                # clean and convert the raw strings into numeric 'value'\n",
    "                raw_vals = long[\"v_raw\"].astype(str).str.strip()\n",
    "                is_neg = raw_vals.str.startswith(\"(\") & raw_vals.str.endswith(\")\")\n",
    "                base = raw_vals.str.replace(r\"[\\$\\s\\(\\)%]\", \"\", regex=True)\n",
    "                is_pct = long[\"column_header\"].str.contains(\"%\", case=False, regex=False)\n",
    "                clean = pd.Series(index=base.index, dtype=\"string\")\n",
    "                clean.loc[is_pct]  = base[is_pct].str.replace(\",\", \".\", regex=False)\n",
    "                clean.loc[~is_pct] = base[~is_pct].str.replace(\",\",  \"\", regex=False)\n",
    "                nums = pd.to_numeric(clean, errors=\"coerce\")\n",
    "                long[\"value\"] = np.where(is_neg, -nums, nums)\n",
    "                long.drop(columns=\"v_raw\", inplace=True)\n",
    "\n",
    "                # rename the first data column to 'row_label'\n",
    "                long = long.rename(columns={headers[0]: \"row_label\"})\n",
    "\n",
    "                # assign currency column or default\n",
    "                if cur_col:\n",
    "                    long = long.rename(columns={cur_col: \"currency\"})\n",
    "                else:\n",
    "                    long[\"currency\"] = default_currency\n",
    "\n",
    "                # add metadata for table identity and page\n",
    "                long[\"table_name\"]  = f\"tbl{tbl_counter}_page{page.page_number}\"\n",
    "                long[\"page_number\"] = page.page_number\n",
    "\n",
    "                # select and order the final columns\n",
    "                rows.append(long[[\n",
    "                    \"table_name\",\n",
    "                    \"row_label\",\n",
    "                    \"column_header\",\n",
    "                    \"value\",\n",
    "                    \"currency\",\n",
    "                    \"page_number\"\n",
    "                ]])\n",
    "\n",
    "    # concatenate all table outputs into one DataFrame\n",
    "    return pd.concat(rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7107aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your project-root (where you cloned the repo)\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "# Locate the single Q1-2025 PDF in the bronze folder\n",
    "BRONZE_Q1     = PROJECT_ROOT / \"task1\" / \"bronze\" / \"2025_Q1\"\n",
    "PDF_PATH    = list(BRONZE_Q1.glob(\"*.pdf\"))[0]\n",
    "\n",
    "# Define output Parquet path for the normalized tables\n",
    "SILVER_DIR  = PROJECT_ROOT / \"task2\" / \"silver\"\n",
    "OUTPUT_PARQ = SILVER_DIR / \"q1_2025_tables.parquet\"\n",
    "\n",
    "# Run the extraction function and write results to Parquet\n",
    "df_all = extract_all_tables_long(PDF_PATH)\n",
    "df_all.to_parquet(OUTPUT_PARQ, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
